tescore<-array(dim=10)
for (wi in 1:10)
{wtd<-createDataPartition(y=bigy, p=.8, list=FALSE)
ntrbx<-nbx[wtd, ]
ntrby<-bigy[wtd]
trposflag<-ntrby>0
ptregs<-ntrbx[trposflag, ]
ntregs<-ntrbx[!trposflag,]
ntebx<-nbx[-wtd, ]
nteby<-bigy[-wtd]
ptrmean<-sapply(ptregs, mean, na.rm=TRUE) #ignore any NA
ntrmean<-sapply(ntregs, mean, na.rm=TRUE)
ptrsd<-sapply(ptregs, sd, na.rm=TRUE)
ntrsd<-sapply(ntregs, sd, na.rm=TRUE)
ptroffsets<-t(t(ntrbx)-ptrmean)
ptrscales<-t(t(ptroffsets)/ptrsd)
ptrlogs<--(1/2)*rowSums(apply(ptrscales,c(1, 2), function(x)x^2), na.rm=TRUE)-sum(log(ptrsd))
ntroffsets<-t(t(ntrbx)-ntrmean)
ntrscales<-t(t(ntroffsets)/ntrsd)
ntrlogs<--(1/2)*rowSums(apply(ntrscales,c(1, 2), function(x)x^2), na.rm=TRUE)-sum(log(ntrsd))
lvwtr<-ptrlogs>ntrlogs
gotrighttr<-lvwtr==ntrby
trscore[wi]<-sum(gotrighttr)/(sum(gotrighttr)+sum(!gotrighttr))
pteoffsets<-t(t(ntebx)-ptrmean)
ptescales<-t(t(pteoffsets)/ptrsd)
ptelogs<--(1/2)*rowSums(apply(ptescales,c(1, 2), function(x)x^2), na.rm=TRUE)-sum(log(ptrsd))
nteoffsets<-t(t(ntebx)-ntrmean)
ntescales<-t(t(nteoffsets)/ntrsd)
ntelogs<--(1/2)*rowSums(apply(ntescales,c(1, 2), function(x)x^2), na.rm=TRUE)-sum(log(ntrsd))
lvwte<-ptelogs>ntelogs
gotright<-lvwte==nteby
tescore[wi]<-sum(gotright)/(sum(gotright)+sum(!gotright))
}
trscore
tescore
#setwd('~/Current/Courses/LearningCourse/Pima')
wdat<-read.csv('data.txt', header=FALSE)
library(klaR)
library(caret)
bigx<-wdat[,-c(9)]
bigy<-wdat[,9]
trscore<-array(dim=10)
tescore<-array(dim=10)
for (wi in 1:10)
{
#wi<-1 # 1 split (no cross-validation)
wtd<-createDataPartition(y=bigy, p=.8, list=FALSE) #random .8
nbx<-bigx
ntrbx<-nbx[wtd, ] #.8*700 x 8 matrix of features
ntrby<-bigy[wtd] # features of respective wtd entries
trposflag<-ntrby>0 # .8*700 x 1 matrix of T/F (T==1, F==0)
ptregs<-ntrbx[trposflag, ] # subset of feature matrix with label 1 (same as pegs in example)
ntregs<-ntrbx[!trposflag,] # subset of feature matrix with label 0 (same as negs in example)
ntebx<-nbx[-wtd, ] # testing features
nteby<-bigy[-wtd] # testing labels
ptrmean<-sapply(ptregs, mean, na.rm=FALSE) # positive training mean excluding N/A's
ntrmean<-sapply(ntregs, mean, na.rm=FALSE) # negative training mean excluding N/A's
ptrsd<-sapply(ptregs, sd, na.rm=FALSE) #positive training standard dev excluding N/A's
ntrsd<-sapply(ntregs, sd, na.rm=FALSE) #negative training standard dev excluding N/A's
ptroffsets<-t(t(ntrbx)-ptrmean) # subtract mean from positive training
ptrscales<-t(t(ptroffsets)/ptrsd) # divide positive training by std dev
# square positive training and subtract the log of std dev
ptrlogs<--(1/2)*rowSums(apply(ptrscales,c(1, 2), function(x)x^2), na.rm=TRUE)-sum(log(ptrsd))
ntroffsets<-t(t(ntrbx)-ntrmean)
ntrscales<-t(t(ntroffsets)/ntrsd)
ntrlogs<--(1/2)*rowSums(apply(ntrscales,c(1, 2), function(x)x^2), na.rm=TRUE)-sum(log(ntrsd))
lvwtr<-ptrlogs>ntrlogs #note that addition of log of prior is unecessary as they are both about equal
gotrighttr<-lvwtr==ntrby #true if classification got right answer, false else
trscore[wi]<-sum(gotrighttr)/(sum(gotrighttr)+sum(!gotrighttr)) # performance of classifier on splits
# perform classification on test data
pteoffsets<-t(t(ntebx)-ptrmean)
ptescales<-t(t(pteoffsets)/ptrsd)
ptelogs<--(1/2)*rowSums(apply(ptescales,c(1, 2), function(x)x^2), na.rm=TRUE)-sum(log(ptrsd))
nteoffsets<-t(t(ntebx)-ntrmean)
ntescales<-t(t(nteoffsets)/ntrsd)
ntelogs<--(1/2)*rowSums(apply(ntescales,c(1, 2), function(x)x^2), na.rm=TRUE)-sum(log(ntrsd))
lvwte<-ptelogs>ntelogs
gotright<-lvwte==nteby
tescore[wi]<-sum(gotright)/(sum(gotright)+sum(!gotright))
}
trscoremean<-sapply(trscore, mean)
tescoremean<-sapply(tescore, mean)
trscoremean
#setwd('~/Current/Courses/LearningCourse/Pima')
wdat<-read.csv('data.txt', header=FALSE)
library(klaR)
library(caret)
bigx<-wdat[,-c(9)]
bigy<-wdat[,9]
trscore<-array(dim=10)
tescore<-array(dim=10)
for (wi in 1:10)
{
#wi<-1 # 1 split (no cross-validation)
wtd<-createDataPartition(y=bigy, p=.8, list=FALSE) #random .8
nbx<-bigx
ntrbx<-nbx[wtd, ] #.8*700 x 8 matrix of features
ntrby<-bigy[wtd] # features of respective wtd entries
trposflag<-ntrby>0 # .8*700 x 1 matrix of T/F (T==1, F==0)
ptregs<-ntrbx[trposflag, ] # subset of feature matrix with label 1 (same as pegs in example)
ntregs<-ntrbx[!trposflag,] # subset of feature matrix with label 0 (same as negs in example)
ntebx<-nbx[-wtd, ] # testing features
nteby<-bigy[-wtd] # testing labels
ptrmean<-sapply(ptregs, mean, na.rm=FALSE) # positive training mean excluding N/A's
ntrmean<-sapply(ntregs, mean, na.rm=FALSE) # negative training mean excluding N/A's
ptrsd<-sapply(ptregs, sd, na.rm=FALSE) #positive training standard dev excluding N/A's
ntrsd<-sapply(ntregs, sd, na.rm=FALSE) #negative training standard dev excluding N/A's
ptroffsets<-t(t(ntrbx)-ptrmean) # subtract mean from positive training
ptrscales<-t(t(ptroffsets)/ptrsd) # divide positive training by std dev
# square positive training and subtract the log of std dev
ptrlogs<--(1/2)*rowSums(apply(ptrscales,c(1, 2), function(x)x^2), na.rm=TRUE)-sum(log(ptrsd))
ntroffsets<-t(t(ntrbx)-ntrmean)
ntrscales<-t(t(ntroffsets)/ntrsd)
ntrlogs<--(1/2)*rowSums(apply(ntrscales,c(1, 2), function(x)x^2), na.rm=TRUE)-sum(log(ntrsd))
lvwtr<-ptrlogs>ntrlogs #note that addition of log of prior is unecessary as they are both about equal
gotrighttr<-lvwtr==ntrby #true if classification got right answer, false else
trscore[wi]<-sum(gotrighttr)/(sum(gotrighttr)+sum(!gotrighttr)) # performance of classifier on splits
# perform classification on test data
pteoffsets<-t(t(ntebx)-ptrmean)
ptescales<-t(t(pteoffsets)/ptrsd)
ptelogs<--(1/2)*rowSums(apply(ptescales,c(1, 2), function(x)x^2), na.rm=TRUE)-sum(log(ptrsd))
nteoffsets<-t(t(ntebx)-ntrmean)
ntescales<-t(t(nteoffsets)/ntrsd)
ntelogs<--(1/2)*rowSums(apply(ntescales,c(1, 2), function(x)x^2), na.rm=TRUE)-sum(log(ntrsd))
lvwte<-ptelogs>ntelogs
gotright<-lvwte==nteby
tescore[wi]<-sum(gotright)/(sum(gotright)+sum(!gotright))
}
trscoremean<-apply(trscore, mean)
tescoremean<-apply(tescore, mean)
#setwd('~/Current/Courses/LearningCourse/Pima')
wdat<-read.csv('data.txt', header=FALSE)
library(klaR)
library(caret)
bigx<-wdat[,-c(9)]
bigy<-wdat[,9]
trscore<-array(dim=10)
tescore<-array(dim=10)
for (wi in 1:10)
{
#wi<-1 # 1 split (no cross-validation)
wtd<-createDataPartition(y=bigy, p=.8, list=FALSE) #random .8
nbx<-bigx
ntrbx<-nbx[wtd, ] #.8*700 x 8 matrix of features
ntrby<-bigy[wtd] # features of respective wtd entries
trposflag<-ntrby>0 # .8*700 x 1 matrix of T/F (T==1, F==0)
ptregs<-ntrbx[trposflag, ] # subset of feature matrix with label 1 (same as pegs in example)
ntregs<-ntrbx[!trposflag,] # subset of feature matrix with label 0 (same as negs in example)
ntebx<-nbx[-wtd, ] # testing features
nteby<-bigy[-wtd] # testing labels
ptrmean<-sapply(ptregs, mean, na.rm=FALSE) # positive training mean excluding N/A's
ntrmean<-sapply(ntregs, mean, na.rm=FALSE) # negative training mean excluding N/A's
ptrsd<-sapply(ptregs, sd, na.rm=FALSE) #positive training standard dev excluding N/A's
ntrsd<-sapply(ntregs, sd, na.rm=FALSE) #negative training standard dev excluding N/A's
ptroffsets<-t(t(ntrbx)-ptrmean) # subtract mean from positive training
ptrscales<-t(t(ptroffsets)/ptrsd) # divide positive training by std dev
# square positive training and subtract the log of std dev
ptrlogs<--(1/2)*rowSums(apply(ptrscales,c(1, 2), function(x)x^2), na.rm=TRUE)-sum(log(ptrsd))
ntroffsets<-t(t(ntrbx)-ntrmean)
ntrscales<-t(t(ntroffsets)/ntrsd)
ntrlogs<--(1/2)*rowSums(apply(ntrscales,c(1, 2), function(x)x^2), na.rm=TRUE)-sum(log(ntrsd))
lvwtr<-ptrlogs>ntrlogs #note that addition of log of prior is unecessary as they are both about equal
gotrighttr<-lvwtr==ntrby #true if classification got right answer, false else
trscore[wi]<-sum(gotrighttr)/(sum(gotrighttr)+sum(!gotrighttr)) # performance of classifier on splits
# perform classification on test data
pteoffsets<-t(t(ntebx)-ptrmean)
ptescales<-t(t(pteoffsets)/ptrsd)
ptelogs<--(1/2)*rowSums(apply(ptescales,c(1, 2), function(x)x^2), na.rm=TRUE)-sum(log(ptrsd))
nteoffsets<-t(t(ntebx)-ntrmean)
ntescales<-t(t(nteoffsets)/ntrsd)
ntelogs<--(1/2)*rowSums(apply(ntescales,c(1, 2), function(x)x^2), na.rm=TRUE)-sum(log(ntrsd))
lvwte<-ptelogs>ntelogs
gotright<-lvwte==nteby
tescore[wi]<-sum(gotright)/(sum(gotright)+sum(!gotright))
}
trscoremean<-mean(trscore)
tescoremean<-mean(tescore)
trscoremean
tescoremean
trscore
trscoremean
tescore
tescoremean
setwd('~/Current/Courses/LearningCourse/Pima')
wdat<-read.csv('data.txt', header=FALSE)
library(klaR)
library(caret)
bigx<-wdat[,-c(9)]
bigy<-wdat[,9]
nbx<-bigx
for (i in c(3, 4, 6, 8))# for i in 3,4,6,8
{vw<-bigx[, i]==0 #whether entry in bigx in that col is 0
nbx[vw, i]=NA #replace with NA (NA+1=NA)
}
trscore<-array(dim=10)
tescore<-array(dim=10)
for (wi in 1:10)
{wtd<-createDataPartition(y=bigy, p=.8, list=FALSE)
ntrbx<-nbx[wtd, ]
ntrby<-bigy[wtd]
trposflag<-ntrby>0
ptregs<-ntrbx[trposflag, ]
ntregs<-ntrbx[!trposflag,]
ntebx<-nbx[-wtd, ]
nteby<-bigy[-wtd]
ptrmean<-sapply(ptregs, mean, na.rm=TRUE) #ignore any NA
ntrmean<-sapply(ntregs, mean, na.rm=TRUE)
ptrsd<-sapply(ptregs, sd, na.rm=TRUE)
ntrsd<-sapply(ntregs, sd, na.rm=TRUE)
ptroffsets<-t(t(ntrbx)-ptrmean)
ptrscales<-t(t(ptroffsets)/ptrsd)
ptrlogs<--(1/2)*rowSums(apply(ptrscales,c(1, 2), function(x)x^2), na.rm=TRUE)-sum(log(ptrsd))
ntroffsets<-t(t(ntrbx)-ntrmean)
ntrscales<-t(t(ntroffsets)/ntrsd)
ntrlogs<--(1/2)*rowSums(apply(ntrscales,c(1, 2), function(x)x^2), na.rm=TRUE)-sum(log(ntrsd))
lvwtr<-ptrlogs>ntrlogs
gotrighttr<-lvwtr==ntrby
trscore[wi]<-sum(gotrighttr)/(sum(gotrighttr)+sum(!gotrighttr))
pteoffsets<-t(t(ntebx)-ptrmean)
ptescales<-t(t(pteoffsets)/ptrsd)
ptelogs<--(1/2)*rowSums(apply(ptescales,c(1, 2), function(x)x^2), na.rm=TRUE)-sum(log(ptrsd))
nteoffsets<-t(t(ntebx)-ntrmean)
ntescales<-t(t(nteoffsets)/ntrsd)
ntelogs<--(1/2)*rowSums(apply(ntescales,c(1, 2), function(x)x^2), na.rm=TRUE)-sum(log(ntrsd))
lvwte<-ptelogs>ntelogs
gotright<-lvwte==nteby
tescore[wi]<-sum(gotright)/(sum(gotright)+sum(!gotright))
}
trscoremean<-mean(trscore)
tescoremean<-mean(tescore)
trscore
trscoremean
tescore
tescoremean
train?
?train
?trainControl()
setwd('~/Current/Courses/LearningCourse/Pima')
wdat<-read.csv('data.txt', header=FALSE)
library(klaR)
library(caret)
bigx<-wdat[,-c(9)] #drop col 9 that contains labels
bigy<-as.factor(wdat[,9]) #coerce col 9 into storing it as a factor (takes in fixed number of vars)
wtd<-createDataPartition(y=bigy, p=.8, list=FALSE) #randomly split 80% of data
trax<-bigx[wtd,] #training features
tray<-bigy[wtd] #choose rows with indices wtd
#trust validation built in, in this case 10 times
model<-train(trax, tray, 'nb', trControl=trainControl(method='cv', number=10))
teclasses<-predict(model,newdata=bigx[-wtd,]) #gives predictions on test data
confusionMatrix(data=teclasses, bigy[-wtd])
confusionMatrix()
setwd('~/Current/Courses/LearningCourse/Pima')
wdat<-read.csv('data.txt', header=FALSE)
library(klaR)
library(caret)
bigx<-wdat[,-c(9)] #drop col 9 that contains labels
bigy<-as.factor(wdat[,9]) #coerce col 9 into storing it as a factor (takes in fixed number of vars)
wtd<-createDataPartition(y=bigy, p=.8, list=FALSE) #randomly split 80% of data
trax<-bigx[wtd,] #training features
tray<-bigy[wtd] #choose rows with indices wtd
#trust validation built in, in this case 10 times
model<-train(trax, tray, 'nb', trControl=trainControl(method='cv', number=10))
teclasses<-predict(model,newdata=bigx[-wtd,]) #gives predictions on test data
matrixresult<-confusionMatrix(data=teclasses, bigy[-wtd])
setwd('~/Current/Courses/LearningCourse/Pima')
wdat<-read.csv('data.txt', header=FALSE)
library(klaR)
library(caret)
bigx<-wdat[,-c(9)] #drop col 9 that contains labels
bigy<-as.factor(wdat[,9]) #coerce col 9 into storing it as a factor (takes in fixed number of vars)
wtd<-createDataPartition(y=bigy, p=.8, list=FALSE) #randomly split 80% of data
trax<-bigx[wtd,] #training features
tray<-bigy[wtd] #choose rows with indices wtd
#trust validation built in, in this case 10 times
model<-train(trax, tray, 'nb', trControl=trainControl(method='cv', number=10))
teclasses<-predict(model,newdata=bigx[-wtd,]) #gives predictions on test data
matrixresult<-confusionMatrix(data=teclasses, bigy[-wtd])
matrixresult
matrixresult.accuracy
summary(matrixresult)
matrixresult
matrixresult$accuracy
matrixresult$overall
matrixresult$overall$accuracy
matrixresult$overall[accuracy]
matrixresult$overall[Accuracy]
matrixresult$overall['Accuracy']
setwd('~/Current/Courses/LearningCourse/Pima')
wdat<-read.csv('data.txt', header=FALSE)
library(klaR)
library(caret)
trscore<-array(dim=10)
tescore<-array(dim=10)
for (wi in 1:10)
{
bigx<-wdat[,-c(9)] #drop col 9 that contains labels
bigy<-as.factor(wdat[,9]) #coerce col 9 into storing it as a factor (takes in fixed number of vars)
wtd<-createDataPartition(y=bigy, p=.8, list=FALSE) #randomly split 80% of data
trax<-bigx[wtd,] #training features
tray<-bigy[wtd] #choose rows with indices wtd
#trust validation built in, in this case 10 times
model<-train(trax, tray, 'nb', trControl=trainControl(method='cv', number=10))
trclasses<-predict(model,newdata=bigx[wtd,])
teclasses<-predict(model,newdata=bigx[-wtd,]) #gives predictions on test data
trmatrixresult<-confusionMatrix(data=trclasses, bigy[wtd])
tematrixresult<-confusionMatrix(data=teclasses, bigy[-wtd])
trscore[wi]<-matrixresult$overall['Accuracy']
tescore[wi]<-matrixresult$overall['Accuracy']
}
trscore
tescore
setwd('~/Current/Courses/LearningCourse/Pima')
wdat<-read.csv('data.txt', header=FALSE)
library(klaR)
library(caret)
trscore<-array(dim=10)
tescore<-array(dim=10)
for (wi in 1:10)
{
bigx<-wdat[,-c(9)] #drop col 9 that contains labels
bigy<-as.factor(wdat[,9]) #coerce col 9 into storing it as a factor (takes in fixed number of vars)
wtd<-createDataPartition(y=bigy, p=.8, list=FALSE) #randomly split 80% of data
trax<-bigx[wtd,] #training features
tray<-bigy[wtd] #choose rows with indices wtd
#trust validation built in, in this case 10 times
model<-train(trax, tray, 'nb', trControl=trainControl(method='cv', number=10))
trclasses<-predict(model,newdata=bigx[wtd,])
teclasses<-predict(model,newdata=bigx[-wtd,]) #gives predictions on test data
trmatrixresult<-confusionMatrix(data=trclasses, bigy[wtd])
tematrixresult<-confusionMatrix(data=teclasses, bigy[-wtd])
trscore[wi]<-trmatrixresult$overall['Accuracy']
tescore[wi]<-tematrixresult$overall['Accuracy']
}
trscore
tescore
setwd('~/Current/Courses/LearningCourse/Pima')
wdat<-read.csv('data.txt', header=FALSE)
library(klaR)
library(caret)
trscore<-array(dim=10)
tescore<-array(dim=10)
bigx<-wdat[,-c(9)] #drop col 9 that contains labels
bigy<-as.factor(wdat[,9]) #coerce col 9 into storing it as a factor (takes in fixed number of vars)
for (wi in 1:10)
{
wtd<-createDataPartition(y=bigy, p=.8, list=FALSE) #randomly split 80% of data
trax<-bigx[wtd,] #training features
tray<-bigy[wtd] #choose rows with indices wtd
#trust validation built in, in this case 10 times
model<-train(trax, tray, 'nb', trControl=trainControl(method='cv', number=10))
trclasses<-predict(model,newdata=bigx[wtd,])
teclasses<-predict(model,newdata=bigx[-wtd,]) #gives predictions on test data
trmatrixresult<-confusionMatrix(data=trclasses, bigy[wtd])
tematrixresult<-confusionMatrix(data=teclasses, bigy[-wtd])
trscore[wi]<-trmatrixresult$overall['Accuracy']
tescore[wi]<-tematrixresult$overall['Accuracy']
}
trscore
tescore
setwd('~/Current/Courses/LearningCourse/Pima')
wdat<-read.csv('data.txt', header=FALSE)
library(klaR)
library(caret)
trscore<-array(dim=10)
tescore<-array(dim=10)
bigx<-wdat[,-c(9)] #drop col 9 that contains labels
bigy<-as.factor(wdat[,9]) #coerce col 9 into storing it as a factor (takes in fixed number of vars)
for (wi in 1:10)
{
wtd<-createDataPartition(y=bigy, p=.8, list=FALSE) #randomly split 80% of data
trax<-bigx[wtd,] #training features
tray<-bigy[wtd] #choose rows with indices wtd
#trust validation built in, in this case 10 times
model<-train(trax, tray, 'nb', trControl=trainControl(method='cv', number=10))
trclasses<-predict(model,newdata=bigx[wtd,])
teclasses<-predict(model,newdata=bigx[-wtd,]) #gives predictions on test data
trmatrixresult<-confusionMatrix(data=trclasses, bigy[wtd])
tematrixresult<-confusionMatrix(data=teclasses, bigy[-wtd])
trscore[wi]<-trmatrixresult$overall['Accuracy']
tescore[wi]<-tematrixresult$overall['Accuracy']
}
trscoremean<-mean(trscore)
tescoremean<-mean(tescore)
trscore
trscoremean
tescore
tescoremean
setwd('/Users/harry/projects/aml/assignment1/')
rm(list=ls()) # housekeeping
wdat<-read.csv('data.txt', header=FALSE)
library(klaR)
library(caret)
bigx<-wdat[,-c(9)] #drop col 9
bigy<-as.factor(wdat[,9]) #coerce col 9 and store as factor (class label)
trscore<-array(dim=10)
tescore<-array(dim=10)
for (wi in 1:10)
{
wtd<-createDataPartition(y=bigy, p=.8, list=FALSE) #randomly partitions with probability .8
#svmlight
svm<-svmlight(bigx[wtd,], bigy[wtd], pathsvm='/Users/harry/projects/aml/assignment1/')
#run on testing data (remaining 20%)
labels<-predict(svm, bigx[-wtd,]) #run svm model object on test data
foo<-labels$class
# evaluate performance on test data
tescore[wi]<-sum(foo==bigy[-wtd])/(sum(foo==bigy[-wtd])+sum(!(foo==bigy[-wtd])))
}
trscoremean<-mean(trscore)
tescoremean<-mean(tescore)
trscore
setwd('/Users/harry/projects/aml/assignment1/')
rm(list=ls()) # housekeeping
wdat<-read.csv('data.txt', header=FALSE)
library(klaR)
library(caret)
bigx<-wdat[,-c(9)] #drop col 9
bigy<-as.factor(wdat[,9]) #coerce col 9 and store as factor (class label)
trscore<-array(dim=10)
tescore<-array(dim=10)
for (wi in 1:10)
{
wtd<-createDataPartition(y=bigy, p=.8, list=FALSE) #randomly partitions with probability .8
#svmlight
svm<-svmlight(bigx[wtd,], bigy[wtd], pathsvm='/Users/harry/projects/aml/assignment1/')
trlabels<-predict(svm, bigx[wtd,])
trfoo<-trlabels$class
trscore[wi]<-sum(trfoo==bigy[wtd])/(sum(trfoo==bigy[wtd])+sum(!(trfoo==bigy[wtd])))
#run on testing data (remaining 20%)
labels<-predict(svm, bigx[-wtd,]) #run svm model object on test data
foo<-labels$class
# evaulate performance on training data
# evaluate performance on test data
tescore[wi]<-sum(foo==bigy[-wtd])/(sum(foo==bigy[-wtd])+sum(!(foo==bigy[-wtd])))
}
trscoremean<-mean(trscore)
tescoremean<-mean(tescore)
trscore
trscoremean
tescore
tescoremean
setwd('~/Current/Courses/LearningCourse/Pima')
wdat<-read.csv('data.txt', header=FALSE)
library(klaR)
library(caret)
trscore<-array(dim=10)
tescore<-array(dim=10)
bigx<-wdat[,-c(9)] #drop col 9 that contains labels
bigy<-as.factor(wdat[,9]) #coerce col 9 into storing it as a factor (takes in fixed number of vars)
#for (wi in 1:10) #trControl's number argument takes care of this
#{
wtd<-createDataPartition(y=bigy, p=.8, list=FALSE) #randomly split 80% of data
trax<-bigx[wtd,] #training features
tray<-bigy[wtd] #choose rows with indices wtd
#trust validation built in, in this case 10 times
model<-train(trax, tray, 'nb', trControl=trainControl(method='cv', number=10))
trclasses<-predict(model,newdata=bigx[wtd,])
teclasses<-predict(model,newdata=bigx[-wtd,]) #gives predictions on test data
trmatrixresult<-confusionMatrix(data=trclasses, bigy[wtd])
tematrixresult<-confusionMatrix(data=teclasses, bigy[-wtd])
trscore[wi]<-trmatrixresult$overall['Accuracy']
tescore[wi]<-tematrixresult$overall['Accuracy']
#}
trscoremean<-mean(trscore)
tescoremean<-mean(tescore)
tescore
setwd('~/Users/harry/projects/aml/assignment1')
wdat<-read.csv('data.txt', header=FALSE)
library(klaR)
library(caret)
bigx<-wdat[,-c(9)]
bigy<-wdat[,9]
trscore<-array(dim=10)
tescore<-array(dim=10)
for (wi in 1:10)
{
#wi<-1 # 1 split (no cross-validation)
wtd<-createDataPartition(y=bigy, p=.8, list=FALSE) #random .8
nbx<-bigx
ntrbx<-nbx[wtd, ] #.8*700 x 8 matrix of features
ntrby<-bigy[wtd] # features of respective wtd entries
trposflag<-ntrby>0 # .8*700 x 1 matrix of T/F (T==1, F==0)
ptregs<-ntrbx[trposflag, ] # subset of feature matrix with label 1 (same as pegs in example)
ntregs<-ntrbx[!trposflag,] # subset of feature matrix with label 0 (same as negs in example)
ntebx<-nbx[-wtd, ] # testing features
nteby<-bigy[-wtd] # testing labels
ptrmean<-sapply(ptregs, mean, na.rm=FALSE) # positive training mean excluding N/A's
ntrmean<-sapply(ntregs, mean, na.rm=FALSE) # negative training mean excluding N/A's
ptrsd<-sapply(ptregs, sd, na.rm=FALSE) #positive training standard dev excluding N/A's
ntrsd<-sapply(ntregs, sd, na.rm=FALSE) #negative training standard dev excluding N/A's
ptroffsets<-t(t(ntrbx)-ptrmean) # subtract mean from positive training
ptrscales<-t(t(ptroffsets)/ptrsd) # divide positive training by std dev
# square positive training and subtract the log of std dev
ptrlogs<--(1/2)*rowSums(apply(ptrscales,c(1, 2), function(x)x^2), na.rm=TRUE)-sum(log(ptrsd))
ntroffsets<-t(t(ntrbx)-ntrmean)
ntrscales<-t(t(ntroffsets)/ntrsd)
ntrlogs<--(1/2)*rowSums(apply(ntrscales,c(1, 2), function(x)x^2), na.rm=TRUE)-sum(log(ntrsd))
lvwtr<-ptrlogs>ntrlogs #note that addition of log of prior is unecessary as they are both about equal
gotrighttr<-lvwtr==ntrby #true if classification got right answer, false else
trscore[wi]<-sum(gotrighttr)/(sum(gotrighttr)+sum(!gotrighttr)) # performance of classifier on splits
# perform classification on test data
pteoffsets<-t(t(ntebx)-ptrmean)
ptescales<-t(t(pteoffsets)/ptrsd)
ptelogs<--(1/2)*rowSums(apply(ptescales,c(1, 2), function(x)x^2), na.rm=TRUE)-sum(log(ptrsd))
nteoffsets<-t(t(ntebx)-ntrmean)
ntescales<-t(t(nteoffsets)/ntrsd)
ntelogs<--(1/2)*rowSums(apply(ntescales,c(1, 2), function(x)x^2), na.rm=TRUE)-sum(log(ntrsd))
lvwte<-ptelogs>ntelogs
gotright<-lvwte==nteby
tescore[wi]<-sum(gotright)/(sum(gotright)+sum(!gotright))
}
trscoremean<-mean(trscore)
tescoremean<-mean(tescore)
